{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 86.79%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0      1  accuracy  macro avg  weighted avg\n",
      "precision  0.88   0.86      0.87       0.87          0.87\n",
      "recall     0.82   0.90      0.87       0.86          0.87\n",
      "f1-score   0.85   0.88      0.87       0.87          0.87\n",
      "support   97.00 115.00      0.87     212.00        212.00\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 80  17]\n",
      " [ 11 104]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 86.81%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0     1  accuracy  macro avg  weighted avg\n",
      "precision  0.87  0.87      0.87       0.87          0.87\n",
      "recall     0.83  0.90      0.87       0.86          0.87\n",
      "f1-score   0.85  0.88      0.87       0.87          0.87\n",
      "support   41.00 50.00      0.87      91.00         91.00\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[34  7]\n",
      " [ 5 45]]\n",
      "\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 93.40%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0      1  accuracy  macro avg  weighted avg\n",
      "precision  0.94   0.93      0.93       0.93          0.93\n",
      "recall     0.92   0.95      0.93       0.93          0.93\n",
      "f1-score   0.93   0.94      0.93       0.93          0.93\n",
      "support   97.00 115.00      0.93     212.00        212.00\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 89   8]\n",
      " [  6 109]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 87.91%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0     1  accuracy  macro avg  weighted avg\n",
      "precision  0.86  0.90      0.88       0.88          0.88\n",
      "recall     0.88  0.88      0.88       0.88          0.88\n",
      "f1-score   0.87  0.89      0.88       0.88          0.88\n",
      "support   41.00 50.00      0.88      91.00         91.00\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[36  5]\n",
      " [ 6 44]]\n",
      "\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0      1  accuracy  macro avg  weighted avg\n",
      "precision  1.00   1.00      1.00       1.00          1.00\n",
      "recall     1.00   1.00      1.00       1.00          1.00\n",
      "f1-score   1.00   1.00      1.00       1.00          1.00\n",
      "support   97.00 115.00      1.00     212.00        212.00\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 97   0]\n",
      " [  0 115]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 82.42%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0     1  accuracy  macro avg  weighted avg\n",
      "precision  0.80  0.84      0.82       0.82          0.82\n",
      "recall     0.80  0.84      0.82       0.82          0.82\n",
      "f1-score   0.80  0.84      0.82       0.82          0.82\n",
      "support   41.00 50.00      0.82      91.00         91.00\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[33  8]\n",
      " [ 8 42]]\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'GaussianNB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ac16bb2c48da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;31m# to evaluate baseline models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m \u001b[0mgnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m \u001b[0mbnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBernoulliNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[0mmnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GaussianNB' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "data = pd.read_csv(\"heart.csv\")\n",
    "data.head()\n",
    "pd.set_option(\"display.float\", \"{:.2f}\".format)\n",
    "data.describe()\n",
    "categorical_val = []\n",
    "continous_val = []\n",
    "for column in data.columns:\n",
    "    if len(data[column].unique()) <= 10:\n",
    "        categorical_val.append(column)\n",
    "    else:\n",
    "        continous_val.append(column)\n",
    "        \n",
    "        \n",
    "# plt.figure(figsize=(15, 15))\n",
    "\n",
    "# for i, column in enumerate(categorical_val, 1):\n",
    "#     plt.subplot(3, 3, i)\n",
    "#     data[data[\"target\"] == 0][column].hist(bins=35, color='blue', label='Have Heart Disease = NO', alpha=0.6)\n",
    "#     data[data[\"target\"] == 1][column].hist(bins=35, color='red', label='Have Heart Disease = YES', alpha=0.6)\n",
    "#     plt.legend()\n",
    "#     plt.xlabel(column)\n",
    "    \n",
    "    \n",
    "    \n",
    "# plt.figure(figsize=(15, 15))\n",
    "\n",
    "# for i, column in enumerate(continous_val, 1):\n",
    "#     plt.subplot(3, 2, i)\n",
    "#     data[data[\"target\"] == 0][column].hist(bins=35, color='blue', label='Have Heart Disease = NO', alpha=0.6)\n",
    "#     data[data[\"target\"] == 1][column].hist(bins=35, color='red', label='Have Heart Disease = YES', alpha=0.6)\n",
    "#     plt.legend()\n",
    "#     plt.xlabel(column)\n",
    "    \n",
    "# # Create another figure\n",
    "# plt.figure(figsize=(9, 7))\n",
    "\n",
    "# # Scatter with postivie examples\n",
    "# plt.scatter(data.age[data.target==1],\n",
    "#             data.thalach[data.target==1],\n",
    "#             c=\"salmon\")\n",
    "\n",
    "# # Scatter with negative examples\n",
    "# plt.scatter(data.age[data.target==0],\n",
    "#             data.thalach[data.target==0],\n",
    "#             c=\"lightblue\")\n",
    "\n",
    "# # Add some helpful info\n",
    "# plt.title(\"Heart Disease in function of Age and Max Heart Rate\")\n",
    "# plt.xlabel(\"Age\")\n",
    "# plt.ylabel(\"Max Heart Rate\")\n",
    "# plt.legend([\"Disease\", \"No Disease\"])\n",
    "\n",
    "# # Let's make our correlation matrix a little prettier\n",
    "# corr_matrix = data.corr()\n",
    "# fig, ax = plt.subplots(figsize=(15, 15))\n",
    "# ax = sns.heatmap(corr_matrix,\n",
    "#                  annot=True,\n",
    "#                  linewidths=0.5,\n",
    "#                  fmt=\".2f\",\n",
    "#                  cmap=\"YlGnBu\");\n",
    "# bottom, top = ax.get_ylim()\n",
    "# ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "\n",
    "categorical_val.remove('target')\n",
    "dataset = pd.get_dummies(data, columns = categorical_val)\n",
    "dataset.head()\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "s_sc = StandardScaler()\n",
    "col_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "dataset[col_to_scale] = s_sc.fit_transform(dataset[col_to_scale])\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")\n",
    "        \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset.drop('target', axis=1)\n",
    "y = dataset.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# ===============逻辑回归\n",
    "accuracies = {}\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(lr_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(lr_clf, X_train, y_train, X_test, y_test, train=False)\n",
    "\n",
    "test_score = accuracy_score(y_test, lr_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, lr_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df = pd.DataFrame(data=[[\"Logistic Regression\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "accuracies['Logistic Regression'] = test_score\n",
    "\n",
    "# ===================支持向量机\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svm_clf = SVC(kernel='rbf', gamma=0.1, C=1.0)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=False)\n",
    "\n",
    "test_score = accuracy_score(y_test, svm_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, svm_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Support Vector Machine\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "accuracies['SVM'] = test_score\n",
    "# #  ======================随机森林\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)\n",
    "\n",
    "test_score = accuracy_score(y_test, rf_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, rf_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Random Forest Classifier\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "\n",
    "\n",
    "accuracies['RandomForest'] = test_score\n",
    "\n",
    "\n",
    "# def feature_imp(df, model):\n",
    "#     fi = pd.DataFrame()\n",
    "#     fi[\"feature\"] = df.columns\n",
    "#     fi[\"importance\"] = model.feature_importances_\n",
    "#     return fi.sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "# # feature_imp(X, lr_clf).plot(kind='barh', figsize=(12,7), legend=False)\n",
    "# feature_imp(X, svm_clf).plot(kind='barh', figsize=(12,7), legend=False)\n",
    "# feature_imp(X, rf_clf).plot(kind='barh', figsize=(12,7), legend=False)\n",
    "\n",
    "# ====================================\n",
    "# colors = [\"purple\", \"green\", \"orange\"]\n",
    "\n",
    "# sns.set_style(\"whitegrid\")\n",
    "# # plt.figure(figsize=(16,5))\n",
    "# plt.yticks(np.arange(80,100,5))\n",
    "# plt.ylabel(\"Accuracy %\")\n",
    "# plt.xlabel(\"Algorithms\")\n",
    "# sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette=colors)\n",
    "# plt.show()\n",
    "# ========================================\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "# kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=5)\n",
    "\n",
    "# labels = ['LR','SVM','RF']\n",
    "# accuracy = print_score(X_train, X_test, y_train, y_test, 'accuracy')\n",
    "# precision = print_score(X_train, X_test, y_train, y_test, 'precision')\n",
    "# recall = print_score(X_train, X_test, y_train, y_test, 'recall')\n",
    "# f1score = print_score(X_train, X_test, y_train, y_test, 'f1')\n",
    "# rocauc = print_score(X_train, X_test, y_train, y_test, 'roc_auc')\n",
    "\n",
    "# x = np.arange(len(labels))  # the label locations\n",
    "# width = 0.18  # the width of the bars\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# rects1 = ax.bar(x-width, accuracy, width, label='accuracy')\n",
    "# rects2 = ax.bar(x, precision, width, label='precision')\n",
    "# rects3 = ax.bar(x+width, recall, width, label='recall')\n",
    "# # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "# ax.set_ylabel('Scores')\n",
    "# ax.set_title('Scores by different model')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.legend()\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "# fig1, ax1 = plt.subplots()\n",
    "# ax1.plot(labels, f1score, label=\"f1score\")\n",
    "# ax1.plot(labels, rocauc, label=\"rocauc\")\n",
    "# ax1.legend()\n",
    "\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=5)\n",
    "\n",
    "# to give model baseline report in dataframe \n",
    "def baseline_report(model, X_train, X_test, y_train, y_test, name):\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy     = np.mean(cross_val_score(model, X_train, y_train, cv=kf, scoring='accuracy'))#cv交叉验证折数\n",
    "    precision    = np.mean(cross_val_score(model, X_train, y_train, cv=kf, scoring='precision'))\n",
    "    recall       = np.mean(cross_val_score(model, X_train, y_train, cv=kf, scoring='recall'))\n",
    "    f1score      = np.mean(cross_val_score(model, X_train, y_train, cv=kf, scoring='f1'))\n",
    "    rocauc       = np.mean(cross_val_score(model, X_train, y_train, cv=kf, scoring='roc_auc'))\n",
    "    y_pred = model.predict(X_test)\n",
    "    logloss      = log_loss(y_test, y_pred)   # SVC & LinearSVC unable to use cvs\n",
    "\n",
    "    df_model = pd.DataFrame({'model'        : [name],\n",
    "                             'accuracy'     : [accuracy],\n",
    "                             'precision'    : [precision],\n",
    "                             'recall'       : [recall],\n",
    "                             'f1score'      : [f1score],\n",
    "                             'rocauc'       : [rocauc],\n",
    "                             'logloss'      : [logloss],\n",
    "                             'timetaken'    : [0]       })   # timetaken: to be used for comparison later\n",
    "    return df_model\n",
    "\n",
    "# to evaluate baseline models\n",
    "gnb = GaussianNB()\n",
    "bnb = BernoulliNB()\n",
    "mnb = MultinomialNB()\n",
    "logit = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "decisiontree = DecisionTreeClassifier()\n",
    "randomforest = RandomForestClassifier()\n",
    "svc = SVC()\n",
    "linearsvc = LinearSVC()\n",
    "\n",
    "# to concat all models\n",
    "df_models = pd.concat([baseline_report(gnb, x_train, x_test, y_train, y_test, 'GaussianNB'),\n",
    "                       baseline_report(bnb, x_train, x_test, y_train, y_test, 'BernoulliNB'),\n",
    "                       baseline_report(mnb, x_train, x_test, y_train, y_test, 'MultinomialNB'),\n",
    "                       baseline_report(logit, x_train, x_test, y_train, y_test, 'LogisticRegression'),\n",
    "                       baseline_report(knn, x_train, x_test, y_train, y_test, 'KNN'),\n",
    "                       baseline_report(decisiontree, x_train, x_test, y_train, y_test, 'DecisionTree'),\n",
    "                       baseline_report(randomforest, x_train, x_test, y_train, y_test, 'RandomForest'),\n",
    "                       baseline_report(svc, x_train, x_test, y_train, y_test, 'SVC'),\n",
    "                       baseline_report(linearsvc, x_train, x_test, y_train, y_test, 'LinearSVC')\n",
    "                       ], axis=0).reset_index()\n",
    "\n",
    "df_models = df_models.drop('index', axis=1)\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
